# Proving Haskell Program Properties

## Principles 
**Referential Transparency**:

We can always replace an expression in any context by one that is known to be equal to it.

**Induction**: 

For any recursive data type, we prove the property true for the non-recursive variants, and then for every recursive (composite) variant, we assume the
property is true for the recursive components, and
from this show it still holds for the composite.

**Case-Splitting**:

Conditionals (and Patterns) are handled by case
analysis —condition true/false, all possible matches

## Simple Proof Example
 Let's prove : length ( 1:2:3:[]) == 3

 To do this we need length definition and some equality laws.

 <code>

    length [] = 0 -- length.1
    length (_:xs) = 1 + length xs -- length.2
    x == x = True -- ==-refl
    x == y = y == x -- ==-comm
    x == y && y == z ==> x == z -- ==-trans
 </code>

 ### Strategy 

The simplest proof strategy is “Reduce to True”
use laws/definitions to transform initial predicate to True.
* Our proof is a series of steps, starting with length (1:2:3:[]) == 3, ending with True.
* Each step is justified by appealing to a law or definition clause.
* We are relying on referential transparency here, and matching.
Given law lhs == rhs, we have three options:
1. match whole law against some sub-expression, and replace that
by True
2. match lhs against some sub-expression, and replace that by
rhs (with appropriate substitutions)
3. match rhs against some sub-expression, and replace that by
lhs (with appropriate substitutions)


For proofs, we use a form of matching that is similar to
Haskell pattern-matching, but more general.
* We match one expression (law) against another expression
(goal)
*  The structure of the goal expression must match that of the law.
* Known/Global names in the law must match themselves
* Local/Parameter names in the law can match any expression: we get a binding from such local names to the expressions they match.
* The binding is used to do the “appropriate substitutions” on the previous slide.


A proof is a series of expressions, separated by a comment
(a.k.a. “justification”) about how they are related
* The justification identifies:
  * which law or definition clause was used
  * the (sub-)expression to which it was applied
  * If the lhs (or rhs) of a law is used, then we should note that we applied the law “left-to-right” ( or “right-to-left”)
* We allow the use of the justification “simplify” to avoid tedious use of arithmetic laws.


#### Reduce to True Proof
<code>

    length (1:2:3:[]) == 3
    = ”length.2, left2right, at 1st occurrence of length”
    1 + length (2:3:[]) == 3
    = ”length.2, left2right, at 1st occurrence of length”
    1 + (1 + length (3:[])) == 3
    = ”length.2, left2right, at 1st occurrence of length”
    1 + (1 + (1 + length [])) == 3
    = ”length.1, left2right, at 1st occurrence of length”
    1 + (1 + (1 + 0)) == 3
    = ”simplify”
    3 == 3
    = ”==-refl, at top-level”
    True
</code>

### Other Strategies
We have other proof strategies we can use, when our goal has the form something == somethingelse
* “Reduce Left-to-Right”
We start with the lefthand side (something) and we transform it into the righthand side (somethingelse)
* “Reduce Right-to-Left”
We start with the righthand side (somethingelse) and we
transform it into the leftthand side (something)
* Pro tip: it is usually best to start with whichever is most complicated, and try to simplify it down to the simpler one.

#### Reduce left to right proof

<code>

    length (1:2:3:[])
    = ”length.2, left2right, at 1st occurrence of length”
    1 + length (2:3:[])
    = ”length.2, left2right, at 1st occurrence of length”
    1 + (1 + length (3:[]))
    = ”length.2, left2right, at 1st occurrence of length”
    1 + (1 + (1 + length []))
    = ”length.1, left2right, at 1st occurrence of length”
    1 + (1 + (1 + 0))
    = ”simplify”
    3
</code>


#### Reduce right to left proof

<code>

    3
    = ”complexify !!!!”
    1 + (1 + (1 + 0))
    = ”length.1, right2left, at 1st occurrence of 0”
    1 + (1 + (1 + length []))
    = ”length.2, right2left, at 3rd occurrence of +”
    1 + (1 + length (3:[]))
    = ”length.2, right2left, at 2nd occurrence of +”
    1 + length (2:3:[])
    = ”length.2, right2left, at 1st occurrence of +”
    length (1:2:3:[])
</code>




# Introduction to prfchk, Haskell proof checker
We keep theories in files with extension .thr
Typically a keyword at the start of a line introduces something.
We start with THEORY and zero or more imports:

<code>
THEORY < TheoryName >

IMPORT-THEORY < Name >

IMPORT-HASKELL < Name >
</code>

Laws are described by the following one-liner construct:

<code>
LAW < name > < br? > < expr >

</code>

Here, < br? > means that the following part is either entirely on this
line, or else occupies a number of subsequent lines.
There can be a blank line before it, and must be a blank line after
it.
The < expr > part is a Haskell expression of type Bool.
It must not have blank lines embedded in it.

A theorem has the following top-level structure:

<code>

THEOREM < name > < br? > < expr >

STRATEGY < strategy >

< strategy-body >

QED < name >
</code>

where
< strategy >

= ReduceAll | ReduceLHS | ReduceRHS| ReduceBoth

If the strategy chosen is ReduceAll, ReduceLHS, or ReduceRHS,
then the < strategy-body > is simply a < calculation >.
If the strategy chosen is ReduceBoth then the < strategy-body >
is:

<code>
LHS

< calculation >

RHS

< calculation >
</code>

A calculation is a sequence of formulae separated by justification
lines,which always start with an equal sign.
Blank lines are allowed around justification lines.

<code>
< expr1 >

= < justification1 >

...

= < justificationN >

< exprN+1 >
</code>

The justification format is as follows:

law [usage] [focus]

We need to provide a law for every justification. Some possibilities are:

syntax : meaning

LAW name :name of law

DEF name :definition of name

DEF name.i : definition of name, identifying clause

SIMP : builtin simplifier

LAW, DEF, and SIMP are keywords. There are others.





The usage component is optional.

syntax :meaning

l2r :left-to-right (for laws of form lhs = rhs)

r2l :right-to-left (for laws of form lhs = rhs)

If usage is omitted, then it means that the whole law is matched, except if the law is a DEF, in which case it is taken as l2r.
l2r, r2l are keywords.

The focus component is optional.

syntax: meaning

@ name: the first occurrence of that name

@ name: i ith in-order occurrence of name)

If usage is omitted, then it means that the focus is at the top-level, except if the law is a DEF name, in which case it is taken as the first occurrence of name.

Another keyword (keysymbol?) is @.